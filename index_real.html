<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-weight:300;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 30px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>



<html>
  <head>
	  <title>Colorful Image Colorization</title>
  </head>

  <body>
    <!-- <center> -->
    <br>
          <center>
          	<span style="font-size:42px">Colorful Image Colorization</span>

	  		  <table align=center width=600px>
	  			  <tr>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:24px"><a href="https://richzhang.github.io/">Richard Zhang</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:24px"><a href="http://web.mit.edu/phillipi/">Phillip Isola</a></span>
		  		  		</center>
		  		  	  </td>
	  	              <td align=center width=100px>
	  					<center>
	  						<span style="font-size:24px"><a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></span>
		  		  		</center>
		  		  	  </td>
			  </table>

          	<!-- <span style="font-size:24px"><a href="https://richzhang.github.io/">Richard Zhang</a>, <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>, <a href="http://www.eecs.berkeley.edu/~efros/">Alexei A. Efros</a></span><br> -->
          	<!-- <span style="font-size:20px">Department of EECS, University of California, Berkeley</span><br> -->
<!--           	<span style="font-size:20px">University of California, Berkeley</span><br> -->
          </center>

<!--   		  <br><br>
		  <hr> -->

  		  <br>
  		  <table align=center width=800px>
  			  <tr>
  	              <td width=400px>
  					<center>
  	                	<a><img class="rounded" src = "./resources/images/teaser3.png" height="500px"></img></a><br>
					</center>
  	              </td>
                </tr>
  	              <td width=400px>
  					<center>
  	                	Example  input  grayscale  photos  and  output  colorizations  from  our  algorithm. These examples are cases where our model works especially well. For randomly selected examples, see <b>Comparisons on Imagenet</b> in the <a href="#perform_comp"><b>Performance comparisons</b></a> section below.
					</center>
  	              </td>

  		  </table>

  		  <br>
		  <hr>

  		  <table align=center width=800px>
	  		  <center><h1>Abstract</h1></center>
	  		  <tr>
	  		  	<td>
					Given a grayscale photograph as input, this paper attacks the problem of hallucinating a <i>plausible</i> color version of the photograph. This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the problem by posing it as a classification task and explore using class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward operation in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a "colorization Turing test", asking human subjects to choose between a generated and ground truth color image. Our method successfully fools humans 20\% of the time, significantly higher than previous methods.
	  		    </td>
	  		  </tr>
			</table>

      	  <br>
		  <hr>

		  <!-- NETWORK ARCHITECTURE, TRY THE MODEL -->
 		<center><h1>Try our model</h1></center>
  		  <table align=center width=1000px>
  			  <tr>
  	              <td align=center width=750px>
  					<center>
						  <td><img class="round" style="height:275px" src="./resources/images/net_diagram.png"/></td>
	  		  		</center>
	  		  	<!-- </br> -->
			  </tr>
		  </table>

  		  <table align=center width=1000px>
			  <tr><center> <br>
				<span style="font-size:28px">Demo&nbsp;<a href='https://github.com/richzhang/colorization'>[IPython Notebook]</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Caffe&nbsp;<a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2016_colorization/files/demo_v0/colorization_deploy_v0.prototxt">[Model]</a>&nbsp;<a href="http://www.eecs.berkeley.edu/~rich.zhang/projects/2016_colorization/files/demo_v0/colorization_release_v0.caffemodel">[Prototxt]</span></span><i></i>
				<span style="font-size:28px"></a></span>
			  <br>
			  </center></tr>
		  </table>

      	  <br>
		  <hr>

  		  <table align=center width=600px>
	 		<center><h1>Paper and Supplementary Material</h1></center>
  			  <tr>
  	              <td width=300px align=left>
				  <td></a><a href="arxiv"><img class="layered-paper-big" style="height:150px" src="./resources/images/paper_pdf_thumb.png"/></a></td>
				  <td><span style="font-size:20pt"><a href="./resources/supp.pdf">Full paper [10MB]</a></td>
  	              </td>

                  <td width=200px align=center>
				  <td><a href="./resources/supp.pdf"><img class="layered-paper" style="height:150px" src="./resources/images/supp_pdf_thumb.png"/></a></td>
				  <td><span style="font-size:16pt"><a href="./resources/supp.pdf">Additional details and experiments [1MB]</a></td>
                  </td>
                </tr>
  		  </table>

		  <br>
		  <hr>

  		  <a name="perform_comp"></a>
  		  <center><h1>Performance comparisons</h1></center>
  		  Click the montage to the left to see our results on Imagenet validation photos (this is an extension of Figure 6 from our paper). Click the montage to the right to see results on a test set sampled from SUN (extension of Figure 12 in our paper). These images are random samples from the test set and are <i>not</i> hand-selected.<br>
  		  <br>
  		  <table align=center width=1000px>
  			  <tr>
  	              <td width=400px>
  					<center>
  						<span style="font-size:22px"><a href='./resources/imagenet_comparison.html'>Comparisons on Imagenet</a></span><br>
  	                	<a href="./resources/imagenet_comparison.html"><img class="rounded" onmouseover="this.src='./resources/images/imagenet_montage_ours.jpg';" onmouseout="this.src='./resources/images/imagenet_montage_lum.jpg';" src = "./resources/images/imagenet_montage_lum.jpg" height = "400px"></a><br>
  					<span style="font-size:16px">(hovering shows our results)</span>
					</center>
  	              </td>
                  <td width=400px>
  					<center>
  						<span style="font-size:22px"><a href='./resources/learch_comparison.html'>Comparisons on SUN</a></span><br>
                  		<a href="./resources/learch_comparison.html"><img class="rounded" onmouseover="this.src='./resources/images/learch_montage_ours.jpg';" onmouseout="this.src='./resources/images/learch_montage_lum.jpg';" src = "./resources/images/learch_montage_lum.jpg" height = "400px"></a><br>
						<span style="font-size:16px">(hovering shows our results)</span>
  					</center>
                  </td>
                </tr>
  		  </table>
		<br><br>
		We also provide an initial comparison against Cheng et al. 2015 <a href="./resources/deep_colorization_comparison.html">here</a>. We were unable to acquire code or results from the authors, so we simply ran our method on screenshots from the figures in the paper of Cheng et al. See Section 3 in the <a href="./resources/supp.pdf">supplemental pdf</a> for further discussion of the differences between our algorithm and that of Cheng et al.
  		<br><br>
  	  	<hr>

  	  	<center><h1>Semantic interpretability of results <br>
  	  		<!-- Categories for which colorization most helps/hurts recognition -->
  	  	</h1></center>
		Here, we show the ImageNet categories for which our colorization helps and hurts the most on object classification. Categories are ranked according to the difference in performance of VGG classification on the colorized result compared to on the grayscale version. This is an extension of Figure 6 in the paper.<br><br>
			<center>Click a category below to see our results on all test images in that category.</center><br>
    		  <table align=center width=1100px>
    			  <tr>
					  <td colspan="2"><center><b>Top</b></center></td>
					  <td></td>
					  <td colspan="2"><center><b>Bottom</b></center></td>
				  </tr>
    	              <td width=200px>
  					  <ol>
  						  <li><a href="./resources/top_0_index.html">Rapeseed<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_0_rapeseed_teaser.jpg"/></a></li>
  						  <li><a href="./resources/top_1_index.html">Lorikeet<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_1_lorikeet_teaser.jpg"/></a></li>
  						  <li><a href="./resources/top_2_index.html">Cheeseburger<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_2_cheeseburger_teaser.jpg"/></a></li>
  						  <li><a href="./resources/top_3_index.html">Meat Loaf<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_3_meat_teaser.jpg"/></a></li>
  						  <li><a href="./resources/top_4_index.html">Pomegranate<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_4_pomegranate_teaser.jpg"/></a></li>
					  </ol>
				  </td>
				  <td width=200px>
					  <ol start="6">
  						  <li><a href="./resources/top_5_index.html">Green Snake<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_5_green_teaser.jpg"/></a></li>
  						  <li><a href="./resources/top_6_index.html">Pizza<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_6_pizza_teaser.jpg"/></a></li>
  						  <li><a href="./resources/top_7_index.html">Yellow Lady's Slipper<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_7_yellow_teaser.jpg"/></a></li>
  						  <li><a href="./resources/top_8_index.html">Orange<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_8_orange_teaser.jpg"/></a></li>
  						  <li><a href="./resources/top_9_index.html">Goldfinch<br><img class="rounded" height=50px src="./resources/images/VGG_tests/top_9_goldfinch_teaser.jpg"/></a></li>
  					  </ol>
				  <td width=100px></td>
  				  </td>
    	              <td width=200px>
  					  <ol start=991>
  						  <li><a href="./resources/bot_9_index.html">Chain<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_9_chain_teaser.jpg"/></a></li>
  						  <li><a href="./resources/bot_8_index.html">Wok<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_8_wok_teaser.jpg"/></a></li>
  						  <li><a href="./resources/bot_7_index.html">Can opener<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_7_can_teaser.jpg"/></a></li>
  						  <li><a href="./resources/bot_6_index.html">Water bottle<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_6_water_teaser.jpg"/></a></li>
						  <li><a href="./resources/bot_5_index.html">Modem<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_5_modem_teaser.jpg"/></a></li>
					  </ol>
				  </td>
				  <td width=200px>
					  <ol start=996>
						  <li><a href="./resources/bot_4_index.html">Standard Schnauzer<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_4_standard_teaser.jpg"/></a></li>
						  <li><a href="./resources/bot_3_index.html">Pickelhaube<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_3_pickelhaube_teaser.jpg"/></a></li>
						  <li><a href="./resources/bot_2_index.html">Half Track<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_2_half_teaser.jpg"/></a></li>
						  <li><a href="./resources/bot_1_index.html">Barbershop<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_1_barbershop_teaser.jpg"/></a></li>
						  <li><a href="./resources/bot_0_index.html">Military Uniform<br><img class="rounded" height=50px src="./resources/images/VGG_tests/bot_0_military_teaser.jpg"/></a></li>
  					  </ol>
  				  </td>
  			  </tr>
  		   </table>

		  <br>
		  <hr>
		  <br>

  		  <table align=center width=750px>
  			  <tr>
  	              <td width=400px>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
					This research was supported, in part, by ONR MURI N000141010934, NSF SMA-1514512, and a hardware donation by NVIDIA Corp. We thank members of the Berkeley Vision Lab for helpful discussions. We thank Aditya Deshpande for providing help with comparisons to <a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Deshpande_Learning_Large-Scale_Automatic_ICCV_2015_paper.pdf">Deshpande et al.</a>
			</left>
		</td>
			 </tr>
		</table>

		<br><br>


</body>
</html>
